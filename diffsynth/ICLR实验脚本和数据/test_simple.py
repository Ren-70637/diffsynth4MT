#!/usr/bin/env python3
"""
ç®€åŒ–çš„æµ‹è¯•è„šæœ¬ - ç”¨äºè¯Šæ–­é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import multiprocessing
import argparse
from load_config import ExperimentConfig

def test_config():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("1. æµ‹è¯•é…ç½®åŠ è½½...")
    config = ExperimentConfig("config.json")
    print(f"   é…ç½®åŠ è½½æˆåŠŸ: {config.work_dir}")
    return config.config

def test_gpu():
    """æµ‹è¯•GPU"""
    print("2. æµ‹è¯•GPU...")
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"   å‘ç° {gpu_count} ä¸ªGPU")
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / 1024**3
            print(f"   GPU {i}: {props.name} - {memory_gb:.1f}GB")
        return True
    else:
        print("   é”™è¯¯: CUDAä¸å¯ç”¨")
        return False

def simple_worker(gpu_id):
    """ç®€å•çš„å·¥ä½œè¿›ç¨‹"""
    try:
        print(f"å·¥ä½œè¿›ç¨‹å¯åŠ¨ - GPU {gpu_id}")
        
        # å°è¯•è®¾ç½®GPU
        torch.cuda.set_device(gpu_id)
        device = f"cuda:{gpu_id}"
        print(f"æˆåŠŸè®¾ç½®è®¾å¤‡: {device}")
        
        # ç®€å•çš„tensoræ“ä½œæµ‹è¯•
        x = torch.randn(100, 100).to(device)
        y = torch.matmul(x, x.t())
        print(f"GPU {gpu_id} å¼ é‡æ“ä½œæˆåŠŸ")
        
        return {"gpu_id": gpu_id, "success": True}
        
    except Exception as e:
        print(f"GPU {gpu_id} å·¥ä½œè¿›ç¨‹å¤±è´¥: {str(e)}")
        return {"gpu_id": gpu_id, "success": False, "error": str(e)}

def test_multiprocessing():
    """æµ‹è¯•å¤šè¿›ç¨‹"""
    print("3. æµ‹è¯•å¤šè¿›ç¨‹...")
    
    # è®¾ç½®spawnæ–¹æ³•
    multiprocessing.set_start_method('spawn', force=True)
    
    try:
        with multiprocessing.Pool(processes=2) as pool:
            results = pool.map(simple_worker, [0, 1])
        
        print("   å¤šè¿›ç¨‹æµ‹è¯•ç»“æœ:")
        for result in results:
            print(f"   {result}")
        
        return all(r.get('success', False) for r in results)
        
    except Exception as e:
        print(f"   å¤šè¿›ç¨‹æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_imports():
    """æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥"""
    print("4. æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥...")
    
    try:
        from diffsynth import ModelManager, WanVideoPipeline, save_video, VideoData
        print("   diffsynth æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"   diffsynth æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}")
        return False

def main():
    print("=== ç®€åŒ–æµ‹è¯•è„šæœ¬ ===")
    
    # æµ‹è¯•æ­¥éª¤
    tests = [
        ("é…ç½®åŠ è½½", test_config),
        ("GPUå¯ç”¨æ€§", test_gpu),
        ("å…³é”®æ¨¡å—", test_imports),
        ("å¤šè¿›ç¨‹", test_multiprocessing),
    ]
    
    results = {}
    for name, test_func in tests:
        try:
            result = test_func()
            results[name] = result
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"   {status}")
        except Exception as e:
            results[name] = False
            print(f"   âŒ å¼‚å¸¸: {str(e)}")
        print()
    
    print("=== æµ‹è¯•æ€»ç»“ ===")
    for name, result in results.items():
        status = "âœ…" if result else "âŒ"
        print(f"{status} {name}")
    
    if all(results.values()):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤é—®é¢˜ã€‚")
        return 1

if __name__ == "__main__":
    exit(main())


