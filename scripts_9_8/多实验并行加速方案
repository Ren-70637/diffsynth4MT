# WAN2.1-T2V-14B 多实验并行加速方案

## 📊 显存使用分析

### 基于测试的显存使用情况

根据测试运行结果分析：

#### 1. 硬件配置
- **GPU**: NVIDIA H20
- **总显存**: 95.58 GB
- **基准占用**: 0.32 GB (系统基础占用)
- **可用显存**: ~95.26 GB

#### 2. 模型组件显存占用估算

基于WAN2.1-T2V-14B模型架构和类似14B参数模型的经验：

| 组件 | 估算显存占用 | 说明 |
|------|-------------|------|
| **模型权重** | ~28-32 GB | 14B参数×bfloat16(2字节) |
| **文本编码器** | ~8-10 GB | T5-XXL编码器 |
| **VAE编码器** | ~4-6 GB | 视频VAE模型 |
| **推理缓存** | ~15-20 GB | 激活值、梯度缓存等 |
| **视频数据** | ~2-4 GB | 81帧×832×480输入视频 |
| **输出缓存** | ~3-5 GB | 生成的视频潜在表示 |
| **VRAM管理开销** | ~2-3 GB | 内存管理和碎片 |
| **安全边际** | ~3-5 GB | 防止OOM的缓冲 |

**单实验总占用估算**: 65-85 GB

#### 3. 并行能力分析

```
4卡服务器 (4×95.58GB = 382.32GB总显存):
- 理论最大并行: 4-5个实验
- 推荐配置: 4个实验 (每GPU 1个)

8卡服务器 (8×95.58GB = 764.64GB总显存):
- 理论最大并行: 8-9个实验
- 推荐配置: 8个实验 (每GPU 1个)
- 激进配置: 12个实验 (部分GPU运行2个)
```

## 🎯 多实验并行方案设计

### 方案架构

#### 1. 任务分配策略

**4卡服务器配置**:
```
GPU 0: camera_motion (约70个任务)
GPU 1: single_object (约85个任务)  
GPU 2: multiple_objects (约60个任务)
GPU 3: complex_human_motion (约75个任务)
```

**8卡服务器配置**:
```
# 主要任务分配
GPU 0-3: 各处理一个完整类别
GPU 4-7: 处理类别的子集或高优先级任务

# 或者均匀分配
每个类别拆分为2部分，分别在2个GPU上并行处理
```

#### 2. 任务拆分机制

将每个类别按视频文件拆分成多个子任务：

```
camera_motion (14个视频) → 拆分为2个子任务
├── 子任务1: 前7个视频 (GPU 0)
└── 子任务2: 后7个视频 (GPU 4)

single_object (17个视频) → 拆分为2个子任务  
├── 子任务1: 前9个视频 (GPU 1)
└── 子任务2: 后8个视频 (GPU 5)

...依此类推
```

### 实现方案

#### 方案1: 基于现有脚本的最小修改方案 (推荐)

**优势**: 修改最少，稳定性高，易于实现
**适用**: 4卡和8卡服务器

**核心思路**:
1. 保持现有的`incremental_experiment.sh`架构
2. 增加任务拆分功能
3. 支持指定视频范围参数

#### 方案2: 进程池并行方案

**优势**: 更高的GPU利用率
**风险**: 复杂度较高，需要更多测试
**适用**: 主要针对8卡服务器的激进配置

## 🛠️ 方案1实现方案 (推荐)

### 核心修改点

#### 1. 增加视频范围参数

在`incremental_experiment.sh`中增加参数：
- `--video-range`: 指定处理的视频范围，如"1-7"或"8-14"
- `--instance-id`: 实验实例ID，用于区分同类别的多个实验

#### 2. 任务分配脚本

创建`parallel_experiment_manager.sh`：
- 自动检测GPU数量
- 智能分配任务到不同GPU
- 支持4卡/8卡自适应

#### 3. 进度监控

扩展`check_experiment_progress.py`：
- 支持多实例进度汇总
- 实时显示GPU利用率
- 失败任务重新分配

### 使用方式

#### 4卡服务器使用
```bash
# 启动4个并行实验（每GPU一个类别）
./parallel_experiment_manager.sh --mode 4gpu --dataset Final_Dataset
```

#### 8卡服务器使用
```bash
# 方式1: 保守模式（每GPU一个类别）
./parallel_experiment_manager.sh --mode 8gpu-conservative --dataset Final_Dataset

# 方式2: 激进模式（某些GPU运行2个实验）
./parallel_experiment_manager.sh --mode 8gpu-aggressive --dataset Final_Dataset
```

#### 手动启动特定任务
```bash
# GPU 0处理camera_motion的前7个视频
./incremental_experiment.sh \
    --category camera_motion \
    --video-range 1-7 \
    --instance-id instance1 \
    --gpu-id 0 \
    --new-prompts prompts.json \
    --new-videos-dir videos/

# GPU 4处理camera_motion的后7个视频  
./incremental_experiment.sh \
    --category camera_motion \
    --video-range 8-14 \
    --instance-id instance2 \
    --gpu-id 4 \
    --new-prompts prompts.json \
    --new-videos-dir videos/
```

## 📈 性能提升预期

### 时间效率

**当前单GPU方案**:
- 总任务数: ~290个视频×5个prompt×2个seed = 2900个任务
- 预估单任务时间: 2-3分钟
- 总耗时: ~145-220小时 (6-9天)

**4卡并行方案**:
- 并行度: 4倍
- 预估总耗时: ~36-55小时 (1.5-2.3天)
- **提升**: 4倍加速

**8卡并行方案**:
- 保守模式: 8倍加速 → 18-28小时
- 激进模式: 12倍加速 → 12-18小时  
- **提升**: 8-12倍加速

### 资源利用率

| 配置 | GPU利用率 | 显存利用率 | 预期加速比 |
|------|-----------|------------|------------|
| 4卡保守 | ~85% | ~75% | 4倍 |
| 8卡保守 | ~85% | ~75% | 8倍 |
| 8卡激进 | ~95% | ~85% | 12倍 |

## ⚠️ 风险评估与缓解

### 1. 显存不足风险
**风险**: 实际显存使用超过估算
**缓解**: 
- 保留5GB安全边际
- 实时监控显存使用
- 自动降级到单实验模式

### 2. 81帧张量问题
**风险**: 目前81帧存在张量尺寸不匹配
**缓解**:
- 优先修复81帧问题
- 备用方案：降级到85帧（4×21+1）
- 增加帧数验证机制

### 3. 实验失败处理
**风险**: 某个实验失败影响整体进度
**缓解**:
- 独立的实验进程，互不影响
- 失败任务自动重新分配
- 详细的错误日志和恢复机制

## 🔧 实施步骤

### 阶段1: 修复81帧问题
1. 分析并修复VAE张量尺寸不匹配
2. 验证81帧可以正常运行
3. 完成显存使用实测

### 阶段2: 实现任务拆分
1. 修改`incremental_experiment.sh`支持视频范围
2. 创建任务分配管理器
3. 测试单GPU多任务可行性

### 阶段3: 多GPU并行测试
1. 4卡服务器测试
2. 8卡服务器测试
3. 性能优化和稳定性改进

### 阶段4: 生产部署
1. 监控和管理工具完善
2. 文档和使用指南
3. 长期稳定性验证

## 📋 预期收益

1. **时间效率**: 4-12倍加速，从6-9天缩短到12小时-2天
2. **资源利用**: GPU利用率从25%提升到85%+
3. **成本效益**: 显著降低实验时间成本
4. **扩展性**: 方案可适应更多GPU的服务器
5. **可维护性**: 基于现有架构，维护成本低